{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "colab": {
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kn_BdZ38obkc"
   },
   "source": [
    "Pipelines sequentially apply **a list of transforms** and a **final estimator**. Intermediate steps of the pipeline must be ‘transforms’, that is, they must implement fit and transform methods. The final estimator only needs to implement fit.\n",
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "* Pipeline of transforms with a final estimator.\n",
    "\n",
    "* Sequentially apply a list of transforms and a final estimator. \n",
    "\n",
    "    * Intermediate steps of the pipeline must be ‘transforms’, that is, they must implement fit and transform methods. \n",
    "    * The final estimator only needs to implement fit. The transformers in the pipeline can be cached using memory argument.\n",
    "\n",
    "* The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HaY7hcyQobke",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:30:02.236011Z",
     "end_time": "2023-05-18T22:30:03.736799Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WNX6zRPIobks",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:30:03.736763Z",
     "end_time": "2023-05-18T22:30:05.591248Z"
    }
   },
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hcH6_S9obk3"
   },
   "source": [
    "## Simple Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PJZzOKLobk5"
   },
   "source": [
    "The simple pipeline is composed of the folloing steps:\n",
    "- Transformation\n",
    "    - Scaling values between 0 and 1\n",
    "    - PCA (we keep 2 components) -> riduce il numero di colonne , tiene solo due\n",
    "- Estimator\n",
    "    - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfv2Ygq0obk7"
   },
   "source": [
    "### Transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pgmMtRPRVqt7",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:30:05.595035Z",
     "end_time": "2023-05-18T22:30:05.598996Z"
    }
   },
   "source": [
    "iris.feature_names"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['sepal length (cm)',\n 'sepal width (cm)',\n 'petal length (cm)',\n 'petal width (cm)']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oWw0JuYMobk9",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:30:05.600153Z",
     "end_time": "2023-05-18T22:30:05.804810Z"
    }
   },
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "preprocessing_transformer = Pipeline(steps=[('scale_01', MinMaxScaler(feature_range=(0, 1))),\n",
    "                                            ('PCA', PCA(n_components=2))])\n",
    "# gli step sono una lista di label+valori , con una label e l'operatore da applicare\n",
    "# ci sono due operazioni a cascata"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ee5H2EcYoblG"
   },
   "source": [
    "### Estimator"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9PCw3m5FoblI",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:30:05.805893Z",
     "end_time": "2023-05-18T22:30:05.808108Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', multi_class='auto')"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xf_pJVC7oblO"
   },
   "source": [
    "### Creating and evaluating the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-QCkecdPoblP",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:30:05.817814Z",
     "end_time": "2023-05-18T22:30:05.841680Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessing_transformer', preprocessing_transformer),\n",
    "                              ('model', model)\n",
    "                             ], verbose = True)\n",
    "# verbose stampa il tempo di eseguzione\n",
    "\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "\n",
    "# Evaluate the model\n",
    "score = accuracy_score(y_valid, preds)\n",
    "print('Accuracy Score:', score)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline]  (step 1 of 2) Processing preprocessing_transformer, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   0.0s\n",
      "Accuracy Score: 0.8666666666666667\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQNHwkbaoblW"
   },
   "source": [
    "### Analyzing the transformation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rpowm18ByEa4",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:30:05.833604Z",
     "end_time": "2023-05-18T22:30:05.842317Z"
    }
   },
   "source": [
    "X_train"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[6.4, 3.1, 5.5, 1.8],\n       [5.4, 3. , 4.5, 1.5],\n       [5.2, 3.5, 1.5, 0.2],\n       [6.1, 3. , 4.9, 1.8],\n       [6.4, 2.8, 5.6, 2.2],\n       [5.2, 2.7, 3.9, 1.4],\n       [5.7, 3.8, 1.7, 0.3],\n       [6. , 2.7, 5.1, 1.6],\n       [5.9, 3. , 4.2, 1.5],\n       [5.8, 2.6, 4. , 1.2],\n       [6.8, 3. , 5.5, 2.1],\n       [4.7, 3.2, 1.3, 0.2],\n       [6.9, 3.1, 5.1, 2.3],\n       [5. , 3.5, 1.6, 0.6],\n       [5.4, 3.7, 1.5, 0.2],\n       [5. , 2. , 3.5, 1. ],\n       [6.5, 3. , 5.5, 1.8],\n       [6.7, 3.3, 5.7, 2.5],\n       [6. , 2.2, 5. , 1.5],\n       [6.7, 2.5, 5.8, 1.8],\n       [5.6, 2.5, 3.9, 1.1],\n       [7.7, 3. , 6.1, 2.3],\n       [6.3, 3.3, 4.7, 1.6],\n       [5.5, 2.4, 3.8, 1.1],\n       [6.3, 2.7, 4.9, 1.8],\n       [6.3, 2.8, 5.1, 1.5],\n       [4.9, 2.5, 4.5, 1.7],\n       [6.3, 2.5, 5. , 1.9],\n       [7. , 3.2, 4.7, 1.4],\n       [6.5, 3. , 5.2, 2. ],\n       [6. , 3.4, 4.5, 1.6],\n       [4.8, 3.1, 1.6, 0.2],\n       [5.8, 2.7, 5.1, 1.9],\n       [5.6, 2.7, 4.2, 1.3],\n       [5.6, 2.9, 3.6, 1.3],\n       [5.5, 2.5, 4. , 1.3],\n       [6.1, 3. , 4.6, 1.4],\n       [7.2, 3.2, 6. , 1.8],\n       [5.3, 3.7, 1.5, 0.2],\n       [4.3, 3. , 1.1, 0.1],\n       [6.4, 2.7, 5.3, 1.9],\n       [5.7, 3. , 4.2, 1.2],\n       [5.4, 3.4, 1.7, 0.2],\n       [5.7, 4.4, 1.5, 0.4],\n       [6.9, 3.1, 4.9, 1.5],\n       [4.6, 3.1, 1.5, 0.2],\n       [5.9, 3. , 5.1, 1.8],\n       [5.1, 2.5, 3. , 1.1],\n       [4.6, 3.4, 1.4, 0.3],\n       [6.2, 2.2, 4.5, 1.5],\n       [7.2, 3.6, 6.1, 2.5],\n       [5.7, 2.9, 4.2, 1.3],\n       [4.8, 3. , 1.4, 0.1],\n       [7.1, 3. , 5.9, 2.1],\n       [6.9, 3.2, 5.7, 2.3],\n       [6.5, 3. , 5.8, 2.2],\n       [6.4, 2.8, 5.6, 2.1],\n       [5.1, 3.8, 1.6, 0.2],\n       [4.8, 3.4, 1.6, 0.2],\n       [6.5, 3.2, 5.1, 2. ],\n       [6.7, 3.3, 5.7, 2.1],\n       [4.5, 2.3, 1.3, 0.3],\n       [6.2, 3.4, 5.4, 2.3],\n       [4.9, 3. , 1.4, 0.2],\n       [5.7, 2.5, 5. , 2. ],\n       [6.9, 3.1, 5.4, 2.1],\n       [4.4, 3.2, 1.3, 0.2],\n       [5. , 3.6, 1.4, 0.2],\n       [7.2, 3. , 5.8, 1.6],\n       [5.1, 3.5, 1.4, 0.3],\n       [4.4, 3. , 1.3, 0.2],\n       [5.4, 3.9, 1.7, 0.4],\n       [5.5, 2.3, 4. , 1.3],\n       [6.8, 3.2, 5.9, 2.3],\n       [7.6, 3. , 6.6, 2.1],\n       [5.1, 3.5, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.2],\n       [5.2, 3.4, 1.4, 0.2],\n       [5.7, 2.8, 4.5, 1.3],\n       [6.6, 3. , 4.4, 1.4],\n       [5. , 3.2, 1.2, 0.2],\n       [5.1, 3.3, 1.7, 0.5],\n       [6.4, 2.9, 4.3, 1.3],\n       [5.4, 3.4, 1.5, 0.4],\n       [7.7, 2.6, 6.9, 2.3],\n       [4.9, 2.4, 3.3, 1. ],\n       [7.9, 3.8, 6.4, 2. ],\n       [6.7, 3.1, 4.4, 1.4],\n       [5.2, 4.1, 1.5, 0.1],\n       [6. , 3. , 4.8, 1.8],\n       [5.8, 4. , 1.2, 0.2],\n       [7.7, 2.8, 6.7, 2. ],\n       [5.1, 3.8, 1.5, 0.3],\n       [4.7, 3.2, 1.6, 0.2],\n       [7.4, 2.8, 6.1, 1.9],\n       [5. , 3.3, 1.4, 0.2],\n       [6.3, 3.4, 5.6, 2.4],\n       [5.7, 2.8, 4.1, 1.3],\n       [5.8, 2.7, 3.9, 1.2],\n       [5.7, 2.6, 3.5, 1. ],\n       [6.4, 3.2, 5.3, 2.3],\n       [6.7, 3. , 5.2, 2.3],\n       [6.3, 2.5, 4.9, 1.5],\n       [6.7, 3. , 5. , 1.7],\n       [5. , 3. , 1.6, 0.2],\n       [5.5, 2.4, 3.7, 1. ],\n       [6.7, 3.1, 5.6, 2.4],\n       [5.8, 2.7, 5.1, 1.9],\n       [5.1, 3.4, 1.5, 0.2],\n       [6.6, 2.9, 4.6, 1.3],\n       [5.6, 3. , 4.1, 1.3],\n       [5.9, 3.2, 4.8, 1.8],\n       [6.3, 2.3, 4.4, 1.3],\n       [5.5, 3.5, 1.3, 0.2],\n       [5.1, 3.7, 1.5, 0.4],\n       [4.9, 3.1, 1.5, 0.1],\n       [6.3, 2.9, 5.6, 1.8],\n       [5.8, 2.7, 4.1, 1. ],\n       [7.7, 3.8, 6.7, 2.2],\n       [4.6, 3.2, 1.4, 0.2]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kjyEx669oblY",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:30:05.838038Z",
     "end_time": "2023-05-18T22:30:05.842557Z"
    }
   },
   "source": [
    "transformed_Dataset = preprocessing_transformer.fit_transform(X_train)"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xqdpcrCiyewK",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:30:05.841219Z",
     "end_time": "2023-05-18T22:30:05.845191Z"
    }
   },
   "source": [
    "#preprocessing_transformer.transform(X_valid)"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b5NysW3aWxda",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:30:05.847820Z",
     "end_time": "2023-05-18T22:30:05.852026Z"
    }
   },
   "source": [
    "transformed_Dataset"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 3.92209763e-01,  4.84561075e-02],\n       [ 9.04869356e-02, -8.95853266e-02],\n       [-6.29042414e-01,  1.33227096e-01],\n       [ 2.97394765e-01, -1.69364128e-02],\n       [ 5.25821952e-01, -7.19394322e-02],\n       [-8.81287220e-03, -2.16744469e-01],\n       [-5.36677344e-01,  3.00755516e-01],\n       [ 2.68771542e-01, -1.40752213e-01],\n       [ 1.18143450e-01, -2.69059275e-02],\n       [ 2.51091885e-02, -1.81673754e-01],\n       [ 5.25692275e-01,  5.32019212e-02],\n       [-6.94577142e-01, -3.59042800e-02],\n       [ 5.43323143e-01,  1.04376017e-01],\n       [-5.34922624e-01,  1.01994571e-01],\n       [-6.15543324e-01,  2.31944792e-01],\n       [-1.46419376e-01, -4.91909893e-01],\n       [ 4.09356632e-01,  2.26626713e-02],\n       [ 6.26859126e-01,  1.45225238e-01],\n       [ 2.57239670e-01, -3.25774678e-01],\n       [ 4.91330874e-01, -1.45418497e-01],\n       [-3.11137441e-02, -2.39957062e-01],\n       [ 7.51055857e-01,  1.48508623e-01],\n       [ 2.30644832e-01,  1.25073917e-01],\n       [-4.85581288e-02, -2.88060620e-01],\n       [ 3.36887165e-01, -1.06099427e-01],\n       [ 2.72587160e-01, -6.62249974e-02],\n       [ 1.10399893e-01, -3.39585478e-01],\n       [ 3.84809669e-01, -1.84109957e-01],\n       [ 2.65820260e-01,  1.73182628e-01],\n       [ 4.30932794e-01,  2.32226292e-02],\n       [ 1.68211870e-01,  1.29812521e-01],\n       [-6.45345754e-01, -6.54635859e-02],\n       [ 3.25366151e-01, -1.69126492e-01],\n       [ 4.42341335e-02, -1.71776560e-01],\n       [-3.03322289e-02, -8.90925360e-02],\n       [ 2.12935708e-02, -2.56200970e-01],\n       [ 1.57988882e-01, -6.75871952e-03],\n       [ 5.36070955e-01,  1.74017447e-01],\n       [-6.27491530e-01,  2.20162086e-01],\n       [-7.80192666e-01, -1.54073852e-01],\n       [ 4.18445072e-01, -1.00940837e-01],\n       [ 1.37560139e-02, -4.56624716e-02],\n       [-5.78557658e-01,  1.16705786e-01],\n       [-5.62428654e-01,  5.27119992e-01],\n       [ 3.07290735e-01,  1.19710244e-01],\n       [-6.79937007e-01, -8.77737077e-02],\n       [ 2.94888031e-01, -4.30124043e-02],\n       [-1.87108336e-01, -2.87572983e-01],\n       [-6.79397491e-01,  2.46070526e-02],\n       [ 2.27661885e-01, -2.95932816e-01],\n       [ 7.13783534e-01,  3.11846034e-01],\n       [ 4.57850167e-02, -8.48415696e-02],\n       [-6.88367112e-01, -9.89261923e-02],\n       [ 6.04316255e-01,  8.35288792e-02],\n       [ 6.02293520e-01,  1.34420420e-01],\n       [ 5.48762515e-01,  1.24849780e-02],\n       [ 4.98991611e-01, -7.03364764e-02],\n       [-6.45891766e-01,  2.32917526e-01],\n       [-6.60941739e-01,  4.72648404e-02],\n       [ 4.09840631e-01,  9.96302033e-02],\n       [ 5.19537762e-01,  1.51637062e-01],\n       [-6.44855258e-01, -3.99257926e-01],\n       [ 4.76174229e-01,  1.30859633e-01],\n       [-6.49588565e-01, -8.87464423e-02],\n       [ 3.39950769e-01, -2.56409148e-01],\n       [ 5.21746980e-01,  1.03816059e-01],\n       [-7.30421762e-01, -7.12523976e-02],\n       [-6.68832329e-01,  1.48493116e-01],\n       [ 4.71417917e-01,  1.04581654e-01],\n       [-6.24855119e-01,  1.21096724e-01],\n       [-7.20024439e-01, -1.46404682e-01],\n       [-5.50890286e-01,  3.01380584e-01],\n       [ 3.16908945e-02, -3.31353254e-01],\n       [ 6.11734992e-01,  1.20127134e-01],\n       [ 7.38921167e-01,  1.33655379e-01],\n       [-6.51685460e-01,  1.22699680e-01],\n       [-6.44092387e-01, -5.24255901e-02],\n       [-6.34538591e-01,  9.69062437e-02],\n       [ 8.30681979e-02, -1.26183581e-01],\n       [ 1.96340237e-01,  5.46653897e-02],\n       [-6.69427361e-01,  6.99127562e-04],\n       [-5.28712594e-01,  3.89726583e-02],\n       [ 1.40117304e-01, -3.61791840e-03],\n       [-5.46286656e-01,  1.16010454e-01],\n       [ 8.57409223e-01, -1.18382648e-02],\n       [-2.00551910e-01, -3.50877450e-01],\n       [ 6.84956472e-01,  4.73726169e-01],\n       [ 2.03089782e-01,  1.04024238e-01],\n       [-6.87064726e-01,  3.60286904e-01],\n       [ 2.74751719e-01, -2.74638287e-02],\n       [-6.15431001e-01,  3.95569911e-01],\n       [ 7.45131197e-01,  7.06334669e-02],\n       [-6.29756265e-01,  2.32569860e-01],\n       [-6.62492622e-01, -3.96701497e-02],\n       [ 6.18287196e-01,  4.44200446e-02],\n       [-6.53236343e-01,  3.57646898e-02],\n       [ 5.36342456e-01,  1.38528803e-01],\n       [ 4.02888387e-02, -1.21162422e-01],\n       [ 9.21568686e-03, -1.42842322e-01],\n       [-9.39738992e-02, -1.83974099e-01],\n       [ 4.99773126e-01,  8.05280500e-02],\n       [ 5.35320231e-01,  4.19791733e-02],\n       [ 2.66793466e-01, -1.76442844e-01],\n       [ 3.52948505e-01,  5.41074884e-02],\n       [-6.16250678e-01, -7.94743163e-02],\n       [-8.60833096e-02, -2.85202375e-01],\n       [ 5.99731269e-01,  7.29311999e-02],\n       [ 3.25366151e-01, -1.69126492e-01],\n       [-6.35791959e-01,  8.38682479e-02],\n       [ 1.96098237e-01,  1.61816236e-02],\n       [ 1.79433082e-02, -5.77928434e-02],\n       [ 2.52406188e-01,  3.59057496e-02],\n       [ 1.70055908e-01, -2.42112767e-01],\n       [-6.14587473e-01,  1.71085793e-01],\n       [-5.97727262e-01,  1.93390762e-01],\n       [-6.70922728e-01, -5.08226343e-02],\n       [ 4.01353720e-01, -3.97341725e-02],\n       [-2.30553155e-02, -1.42146990e-01],\n       [ 7.46805260e-01,  4.43188976e-01],\n       [-6.95830509e-01, -4.89422757e-02]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8L5Xs6hgoblc",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:30:05.851599Z",
     "end_time": "2023-05-18T22:30:05.855392Z"
    }
   },
   "source": [
    "type(transformed_Dataset) # in generale ogni trasformatore da un array"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FJLKK9PAoblg",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:30:05.856354Z",
     "end_time": "2023-05-18T22:30:05.858899Z"
    }
   },
   "source": [
    "tra_df = pd.DataFrame(transformed_Dataset)"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lKHsu-qkoblk",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:30:05.860124Z",
     "end_time": "2023-05-18T22:30:05.863236Z"
    }
   },
   "source": [
    "tra_df.shape"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(120, 2)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "16mGC01Woblo",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:30:05.863949Z",
     "end_time": "2023-05-18T22:30:05.916011Z"
    }
   },
   "source": [
    "tra_df.head()"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "          0         1\n0  0.392210  0.048456\n1  0.090487 -0.089585\n2 -0.629042  0.133227\n3  0.297395 -0.016936\n4  0.525822 -0.071939",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.392210</td>\n      <td>0.048456</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.090487</td>\n      <td>-0.089585</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.629042</td>\n      <td>0.133227</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.297395</td>\n      <td>-0.016936</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.525822</td>\n      <td>-0.071939</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TO3kjC_Aobls",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:30:05.873880Z",
     "end_time": "2023-05-18T22:30:05.916421Z"
    }
   },
   "source": [
    "# Simple check\n",
    "\n",
    "scaled = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaled_X_train = scaled.fit_transform(X_train)\n",
    "\n",
    "print(scaled_X_train[:4])\n",
    "\n",
    "pcaed = PCA(n_components=2)\n",
    "pca_X_train = pcaed.fit_transform(scaled_X_train)"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58333333 0.45833333 0.75862069 0.70833333]\n",
      " [0.30555556 0.41666667 0.5862069  0.58333333]\n",
      " [0.25       0.625      0.06896552 0.04166667]\n",
      " [0.5        0.41666667 0.65517241 0.70833333]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ME2wZrA9oblv",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:30:05.877552Z",
     "end_time": "2023-05-18T22:30:05.916751Z"
    }
   },
   "source": [
    "pca_X_train[:4]"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.39220976,  0.04845611],\n       [ 0.09048694, -0.08958533],\n       [-0.62904241,  0.1332271 ],\n       [ 0.29739477, -0.01693641]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTTN4IG1obly"
   },
   "source": [
    "## ColumnTransformer: Managing different kinds of transformers on different columns:\n",
    "applica un operatore nelle colonne che io scelgo.\n",
    "es:\n",
    "- applicare la PCA solo ad una colonna\n",
    "- applicare il OneHot encoder a **solo** le colonne testuali\n",
    "\n",
    "\n",
    "Extracted and extended from a kaggle.com tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFh1gyaPobly"
   },
   "source": [
    "Applies transformers to columns of an array or pandas DataFrame.\n",
    "\n",
    "This estimator allows different columns or column subsets of the input to be transformed separately and the features generated by each transformer will be concatenated to form a single feature space. This is useful for heterogeneous or columnar data, to combine several feature extraction mechanisms or transformations into a single transformer."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VMlvwlU_oblz",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:30:37.409683Z",
     "end_time": "2023-05-18T22:30:37.460088Z"
    }
   },
   "source": [
    "dataset = pd.read_csv(\"data/melb_data.csv\")\n",
    "dataset.head(5)\n",
    "# vogliamo prevedere il prezzo dati tutti i campi\n",
    "# obbiettivo avere una pipeline che tratti i campi numerici in un modo e i campi testuali in un altro modo"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "       Suburb           Address  Rooms Type      Price Method SellerG  \\\n0  Abbotsford      85 Turner St      2    h  1480000.0      S  Biggin   \n1  Abbotsford   25 Bloomburg St      2    h  1035000.0      S  Biggin   \n2  Abbotsford      5 Charles St      3    h  1465000.0     SP  Biggin   \n3  Abbotsford  40 Federation La      3    h   850000.0     PI  Biggin   \n4  Abbotsford       55a Park St      4    h  1600000.0     VB  Nelson   \n\n        Date  Distance  Postcode  ...  Bathroom  Car  Landsize  BuildingArea  \\\n0  3/12/2016       2.5    3067.0  ...       1.0  1.0     202.0           NaN   \n1  4/02/2016       2.5    3067.0  ...       1.0  0.0     156.0          79.0   \n2  4/03/2017       2.5    3067.0  ...       2.0  0.0     134.0         150.0   \n3  4/03/2017       2.5    3067.0  ...       2.0  1.0      94.0           NaN   \n4  4/06/2016       2.5    3067.0  ...       1.0  2.0     120.0         142.0   \n\n   YearBuilt  CouncilArea Lattitude  Longtitude             Regionname  \\\n0        NaN        Yarra  -37.7996    144.9984  Northern Metropolitan   \n1     1900.0        Yarra  -37.8079    144.9934  Northern Metropolitan   \n2     1900.0        Yarra  -37.8093    144.9944  Northern Metropolitan   \n3        NaN        Yarra  -37.7969    144.9969  Northern Metropolitan   \n4     2014.0        Yarra  -37.8072    144.9941  Northern Metropolitan   \n\n  Propertycount  \n0        4019.0  \n1        4019.0  \n2        4019.0  \n3        4019.0  \n4        4019.0  \n\n[5 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Suburb</th>\n      <th>Address</th>\n      <th>Rooms</th>\n      <th>Type</th>\n      <th>Price</th>\n      <th>Method</th>\n      <th>SellerG</th>\n      <th>Date</th>\n      <th>Distance</th>\n      <th>Postcode</th>\n      <th>...</th>\n      <th>Bathroom</th>\n      <th>Car</th>\n      <th>Landsize</th>\n      <th>BuildingArea</th>\n      <th>YearBuilt</th>\n      <th>CouncilArea</th>\n      <th>Lattitude</th>\n      <th>Longtitude</th>\n      <th>Regionname</th>\n      <th>Propertycount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abbotsford</td>\n      <td>85 Turner St</td>\n      <td>2</td>\n      <td>h</td>\n      <td>1480000.0</td>\n      <td>S</td>\n      <td>Biggin</td>\n      <td>3/12/2016</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>202.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Yarra</td>\n      <td>-37.7996</td>\n      <td>144.9984</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Abbotsford</td>\n      <td>25 Bloomburg St</td>\n      <td>2</td>\n      <td>h</td>\n      <td>1035000.0</td>\n      <td>S</td>\n      <td>Biggin</td>\n      <td>4/02/2016</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>156.0</td>\n      <td>79.0</td>\n      <td>1900.0</td>\n      <td>Yarra</td>\n      <td>-37.8079</td>\n      <td>144.9934</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Abbotsford</td>\n      <td>5 Charles St</td>\n      <td>3</td>\n      <td>h</td>\n      <td>1465000.0</td>\n      <td>SP</td>\n      <td>Biggin</td>\n      <td>4/03/2017</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>134.0</td>\n      <td>150.0</td>\n      <td>1900.0</td>\n      <td>Yarra</td>\n      <td>-37.8093</td>\n      <td>144.9944</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Abbotsford</td>\n      <td>40 Federation La</td>\n      <td>3</td>\n      <td>h</td>\n      <td>850000.0</td>\n      <td>PI</td>\n      <td>Biggin</td>\n      <td>4/03/2017</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>94.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Yarra</td>\n      <td>-37.7969</td>\n      <td>144.9969</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Abbotsford</td>\n      <td>55a Park St</td>\n      <td>4</td>\n      <td>h</td>\n      <td>1600000.0</td>\n      <td>VB</td>\n      <td>Nelson</td>\n      <td>4/06/2016</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>120.0</td>\n      <td>142.0</td>\n      <td>2014.0</td>\n      <td>Yarra</td>\n      <td>-37.8072</td>\n      <td>144.9941</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LZaxsDm7CeAH",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:31:53.830546Z",
     "end_time": "2023-05-18T22:31:53.863642Z"
    }
   },
   "source": [
    "dataset.describe()"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "              Rooms         Price      Distance      Postcode      Bedroom2  \\\ncount  13580.000000  1.358000e+04  13580.000000  13580.000000  13580.000000   \nmean       2.937997  1.075684e+06     10.137776   3105.301915      2.914728   \nstd        0.955748  6.393107e+05      5.868725     90.676964      0.965921   \nmin        1.000000  8.500000e+04      0.000000   3000.000000      0.000000   \n25%        2.000000  6.500000e+05      6.100000   3044.000000      2.000000   \n50%        3.000000  9.030000e+05      9.200000   3084.000000      3.000000   \n75%        3.000000  1.330000e+06     13.000000   3148.000000      3.000000   \nmax       10.000000  9.000000e+06     48.100000   3977.000000     20.000000   \n\n           Bathroom           Car       Landsize  BuildingArea    YearBuilt  \\\ncount  13580.000000  13518.000000   13580.000000   7130.000000  8205.000000   \nmean       1.534242      1.610075     558.416127    151.967650  1964.684217   \nstd        0.691712      0.962634    3990.669241    541.014538    37.273762   \nmin        0.000000      0.000000       0.000000      0.000000  1196.000000   \n25%        1.000000      1.000000     177.000000     93.000000  1940.000000   \n50%        1.000000      2.000000     440.000000    126.000000  1970.000000   \n75%        2.000000      2.000000     651.000000    174.000000  1999.000000   \nmax        8.000000     10.000000  433014.000000  44515.000000  2018.000000   \n\n          Lattitude    Longtitude  Propertycount  \ncount  13580.000000  13580.000000   13580.000000  \nmean     -37.809203    144.995216    7454.417378  \nstd        0.079260      0.103916    4378.581772  \nmin      -38.182550    144.431810     249.000000  \n25%      -37.856822    144.929600    4380.000000  \n50%      -37.802355    145.000100    6555.000000  \n75%      -37.756400    145.058305   10331.000000  \nmax      -37.408530    145.526350   21650.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rooms</th>\n      <th>Price</th>\n      <th>Distance</th>\n      <th>Postcode</th>\n      <th>Bedroom2</th>\n      <th>Bathroom</th>\n      <th>Car</th>\n      <th>Landsize</th>\n      <th>BuildingArea</th>\n      <th>YearBuilt</th>\n      <th>Lattitude</th>\n      <th>Longtitude</th>\n      <th>Propertycount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>13580.000000</td>\n      <td>1.358000e+04</td>\n      <td>13580.000000</td>\n      <td>13580.000000</td>\n      <td>13580.000000</td>\n      <td>13580.000000</td>\n      <td>13518.000000</td>\n      <td>13580.000000</td>\n      <td>7130.000000</td>\n      <td>8205.000000</td>\n      <td>13580.000000</td>\n      <td>13580.000000</td>\n      <td>13580.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.937997</td>\n      <td>1.075684e+06</td>\n      <td>10.137776</td>\n      <td>3105.301915</td>\n      <td>2.914728</td>\n      <td>1.534242</td>\n      <td>1.610075</td>\n      <td>558.416127</td>\n      <td>151.967650</td>\n      <td>1964.684217</td>\n      <td>-37.809203</td>\n      <td>144.995216</td>\n      <td>7454.417378</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.955748</td>\n      <td>6.393107e+05</td>\n      <td>5.868725</td>\n      <td>90.676964</td>\n      <td>0.965921</td>\n      <td>0.691712</td>\n      <td>0.962634</td>\n      <td>3990.669241</td>\n      <td>541.014538</td>\n      <td>37.273762</td>\n      <td>0.079260</td>\n      <td>0.103916</td>\n      <td>4378.581772</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>8.500000e+04</td>\n      <td>0.000000</td>\n      <td>3000.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1196.000000</td>\n      <td>-38.182550</td>\n      <td>144.431810</td>\n      <td>249.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>6.500000e+05</td>\n      <td>6.100000</td>\n      <td>3044.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>177.000000</td>\n      <td>93.000000</td>\n      <td>1940.000000</td>\n      <td>-37.856822</td>\n      <td>144.929600</td>\n      <td>4380.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.000000</td>\n      <td>9.030000e+05</td>\n      <td>9.200000</td>\n      <td>3084.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>440.000000</td>\n      <td>126.000000</td>\n      <td>1970.000000</td>\n      <td>-37.802355</td>\n      <td>145.000100</td>\n      <td>6555.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.000000</td>\n      <td>1.330000e+06</td>\n      <td>13.000000</td>\n      <td>3148.000000</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>651.000000</td>\n      <td>174.000000</td>\n      <td>1999.000000</td>\n      <td>-37.756400</td>\n      <td>145.058305</td>\n      <td>10331.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>10.000000</td>\n      <td>9.000000e+06</td>\n      <td>48.100000</td>\n      <td>3977.000000</td>\n      <td>20.000000</td>\n      <td>8.000000</td>\n      <td>10.000000</td>\n      <td>433014.000000</td>\n      <td>44515.000000</td>\n      <td>2018.000000</td>\n      <td>-37.408530</td>\n      <td>145.526350</td>\n      <td>21650.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RNV8PaHeqCy8",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:32:13.456370Z",
     "end_time": "2023-05-18T22:32:13.461824Z"
    }
   },
   "source": [
    "dataset['Price']"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0        1480000.0\n1        1035000.0\n2        1465000.0\n3         850000.0\n4        1600000.0\n           ...    \n13575    1245000.0\n13576    1031000.0\n13577    1170000.0\n13578    2500000.0\n13579    1285000.0\nName: Price, Length: 13580, dtype: float64"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F8Ci5WYa1aO5"
   },
   "source": [
    "#dataset = dataset[dataset['Price'].isnull()==False]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2LG8rSz816JO",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:32:23.748461Z",
     "end_time": "2023-05-18T22:32:23.755839Z"
    }
   },
   "source": [
    "columns = dataset.columns.to_list()\n",
    "columns"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "['Suburb',\n 'Address',\n 'Rooms',\n 'Type',\n 'Price',\n 'Method',\n 'SellerG',\n 'Date',\n 'Distance',\n 'Postcode',\n 'Bedroom2',\n 'Bathroom',\n 'Car',\n 'Landsize',\n 'BuildingArea',\n 'YearBuilt',\n 'CouncilArea',\n 'Lattitude',\n 'Longtitude',\n 'Regionname',\n 'Propertycount']"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V17ehSlf2BPl",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:32:44.704068Z",
     "end_time": "2023-05-18T22:32:44.709831Z"
    }
   },
   "source": [
    "# tolgo il prezzo dalle colonne e creo il dataset:\n",
    "if 'Price' in columns:\n",
    "  columns.remove('Price')\n",
    "\n",
    "X = dataset[columns]\n",
    "y = dataset['Price']"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fGUx1xBqyq8c",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:33:10.974021Z",
     "end_time": "2023-05-18T22:33:10.987478Z"
    }
   },
   "source": [
    "X.info() # object = stringa"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13580 entries, 0 to 13579\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Suburb         13580 non-null  object \n",
      " 1   Address        13580 non-null  object \n",
      " 2   Rooms          13580 non-null  int64  \n",
      " 3   Type           13580 non-null  object \n",
      " 4   Method         13580 non-null  object \n",
      " 5   SellerG        13580 non-null  object \n",
      " 6   Date           13580 non-null  object \n",
      " 7   Distance       13580 non-null  float64\n",
      " 8   Postcode       13580 non-null  float64\n",
      " 9   Bedroom2       13580 non-null  float64\n",
      " 10  Bathroom       13580 non-null  float64\n",
      " 11  Car            13518 non-null  float64\n",
      " 12  Landsize       13580 non-null  float64\n",
      " 13  BuildingArea   7130 non-null   float64\n",
      " 14  YearBuilt      8205 non-null   float64\n",
      " 15  CouncilArea    12211 non-null  object \n",
      " 16  Lattitude      13580 non-null  float64\n",
      " 17  Longtitude     13580 non-null  float64\n",
      " 18  Regionname     13580 non-null  object \n",
      " 19  Propertycount  13580 non-null  float64\n",
      "dtypes: float64(11), int64(1), object(8)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DS90cjBzy0lu"
   },
   "source": [
    "#X = X[['Longtitude', 'Lattitude', 'YearBuilt', 'Car', 'Bathroom', 'Bedroom2', 'Rooms', 'Postcode']]\n",
    "#X.isnull().any(axis=0)\n",
    "#X.fillna(0, inplace=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "m7mrMSObobl2",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:33:43.199268Z",
     "end_time": "2023-05-18T22:33:43.204823Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGEJK9Zxobl5"
   },
   "source": [
    "We construct the full pipeline in three steps.\n",
    "* Step 1: Define Preprocessing Steps\n",
    "* Step 2: Define the Model\n",
    "* Step 3: Create and Evaluate the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-PoHVD6obl5"
   },
   "source": [
    "### Step 1: Define Preprocessing Steps\n",
    "\n",
    "Similar to how a pipeline bundles together preprocessing and modeling steps, we use the ColumnTransformer class to bundle together different preprocessing steps. The code below:\n",
    "- imputes missing values in numerical data, and\n",
    "- imputes missing values and applies a one-hot encoding to categorical data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jKK73oqqobl6",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:35:30.533928Z",
     "end_time": "2023-05-18T22:35:30.545958Z"
    }
   },
   "source": [
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "\n",
    "# creo una lista di valori che contiene i nomi delle colonne catergoriali e numerici\n",
    "categorical_cols = [cname for cname in X_train.columns if\n",
    "                    X_train[cname].nunique() < 10 and # nunique permette di contare gli elementi doppi nella colonna -> se ci sono piú di 10 elementi doppi la colonna\n",
    "                    X_train[cname].dtype == \"object\"] #  non sarà in categorical_cols\n",
    "\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train.columns if \n",
    "                X_train[cname].dtype in ['int64', 'float64']]"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bRUEiXIzobl9",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:40:32.861481Z",
     "end_time": "2023-05-18T22:40:32.868302Z"
    }
   },
   "source": [
    "categorical_cols"
   ],
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "['Type', 'Method', 'Regionname']"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5aNfQzDiZbEn",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:40:39.879612Z",
     "end_time": "2023-05-18T22:40:39.885033Z"
    }
   },
   "source": [
    "numerical_cols"
   ],
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "['Rooms',\n 'Distance',\n 'Postcode',\n 'Bedroom2',\n 'Bathroom',\n 'Car',\n 'Landsize',\n 'BuildingArea',\n 'YearBuilt',\n 'Lattitude',\n 'Longtitude',\n 'Propertycount']"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "92FxI0M5obmA",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:47:53.470145Z",
     "end_time": "2023-05-18T22:47:53.557237Z"
    }
   },
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer # trasformatore che toglie i valori nulli !! -> e lo sostituisce con il valore più frequente\n",
    "from sklearn.preprocessing import OneHotEncoder # operatore che trasforma i valori in colonne\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse = False))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[ # é una lista di tuple di tre elem -> etichetta, operatore e le colonne a cui si applica l'operatore\n",
    "       ('num', numerical_transformer, numerical_cols),\n",
    "       ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hRjslTmobmD"
   },
   "source": [
    "### Step 2: Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eWIX8r6CobmD",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:53:01.267392Z",
     "end_time": "2023-05-18T22:53:01.273568Z"
    }
   },
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)"
   ],
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6ai-ydFobmG"
   },
   "source": [
    "### Step 3: Create and Evaluate the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RXNt7vkFobmG",
    "ExecuteTime": {
     "start_time": "2023-05-18T22:53:03.449730Z",
     "end_time": "2023-05-18T22:53:07.829518Z"
    }
   },
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[\n",
    "                              ('preprocessor', preprocessor),\n",
    "                              ('model', model),\n",
    "                             ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = my_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model -> si valuta l'errore medio -> sbaglia l'errore di una casa di 160k euro  , é una cattiva  stima\n",
    "score = mean_absolute_error(y_test, preds)\n",
    "print('MAE:', score)"
   ],
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 161591.2226535872\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Mf63rSRgEiur"
   },
   "source": [
    "sum(preds==np.NAN)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HM5NHhwxxS4Y"
   },
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, preds)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eRfHs-yiavrp"
   },
   "source": [
    "pd.DataFrame({'label':y_test, 'preds':preds}).head(4)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8K-EWe2FobmJ"
   },
   "source": [
    "### Parameter tuning\n",
    "\n",
    "Setting parameters of the various steps is enabled by using their names and the parameter name separated by a ‘__’"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oq0u5V5pobmJ",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:03:39.467526Z",
     "end_time": "2023-05-18T23:03:44.579316Z"
    }
   },
   "source": [
    "# Example using a Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# provare la pipeline modificando i paremetri\n",
    "parameters = {\n",
    "    'model__n_estimators': [1,5,10], # nomedellapipeline__modellodiparemetri\n",
    "    'preprocessor__num__strategy': ['most_frequent','constant'], # nomedellapipeline__nomedellapipeline__paremetri\n",
    "    'preprocessor__cat__imputer__strategy': ['most_frequent','constant'],\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(my_pipeline, parameters, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "\n",
    "gs_clf.fit(X, y)"
   ],
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[('preprocessor',\n                                        ColumnTransformer(transformers=[('num',\n                                                                         SimpleImputer(strategy='most_frequent'),\n                                                                         ['Rooms',\n                                                                          'Distance',\n                                                                          'Postcode',\n                                                                          'Bedroom2',\n                                                                          'Bathroom',\n                                                                          'Car',\n                                                                          'Landsize',\n                                                                          'BuildingArea',\n                                                                          'YearBuilt',\n                                                                          'Lattitude',\n                                                                          'Longtitude',\n                                                                          'Propertycount']),\n                                                                        ('cat',\n                                                                         Pipeline(steps=[('imputer',\n                                                                                          SimpleImputer(strategy='most_frequent...\n                                                                                          OneHotEncoder(handle_unknown='ignore',\n                                                                                                        sparse=False))]),\n                                                                         ['Type',\n                                                                          'Method',\n                                                                          'Regionname'])])),\n                                       ('model',\n                                        RandomForestRegressor(random_state=0))]),\n             n_jobs=-1,\n             param_grid={'model__n_estimators': [1, 5, 10],\n                         'preprocessor__cat__imputer__strategy': ['most_frequent',\n                                                                  'constant'],\n                         'preprocessor__num__strategy': ['most_frequent',\n                                                         'constant']},\n             scoring='neg_mean_absolute_error')"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KvRWEnAPobmM",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:03:48.303509Z",
     "end_time": "2023-05-18T23:03:48.310043Z"
    }
   },
   "source": [
    "gs_clf.best_params_"
   ],
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "{'model__n_estimators': 10,\n 'preprocessor__cat__imputer__strategy': 'most_frequent',\n 'preprocessor__num__strategy': 'most_frequent'}"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Jxrfu7-VobmP",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:03:50.276716Z",
     "end_time": "2023-05-18T23:03:50.290927Z"
    }
   },
   "source": [
    "gs_clf.best_score_"
   ],
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "-190165.69738200435"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaTj0X-v35bO"
   },
   "source": [
    "# Variazione di ColumnTrasfromer:\n",
    "Il problema che fino ad ora perdo le informazioni delle colonne che non sto considerando nel preprocessing( tipo Address).\n",
    "### Come faccio a mantenerle ?\n",
    "1. ( si faceva ma ora non più) si applica un trasformatore identità che non fa nulla\n",
    "2. mettendo il parametro `remainder` con `passthrough` le colonne che non sono interessate, vengono direttamente passate in output\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qFhPlFaf35XI",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:18:38.044603Z",
     "end_time": "2023-05-18T23:18:38.049734Z"
    }
   },
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numerical_transformer, numerical_cols)],\n",
    "       remainder='passthrough')"
   ],
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ct-_7Rjk35TJ"
   },
   "source": [
    "#This generate an error!\n",
    "'''\n",
    "perchè avrai in input anche le colonne di testo rimaste\n",
    "'''\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[\n",
    "                              ('preprocessor', preprocessor),\n",
    "                              ('model', model),\n",
    "                             ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = my_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "score = mean_absolute_error(y_test, preds)\n",
    "print('MAE:', score)"
   ],
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'St Kilda'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/zk/y_05r4dd4q51x5hx9n0nwwk80000gn/T/ipykernel_1401/1190493826.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;31m# Preprocessing of training data, fit model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m \u001B[0mmy_pipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     17\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;31m# Preprocessing of validation data, get predictions\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m    392\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_final_estimator\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;34m\"passthrough\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    393\u001B[0m                 \u001B[0mfit_params_last_step\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfit_params_steps\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msteps\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 394\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_final_estimator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mXt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfit_params_last_step\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    395\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    396\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    325\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0missparse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    326\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 327\u001B[0;31m         X, y = self._validate_data(\n\u001B[0m\u001B[1;32m    328\u001B[0m             \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmulti_output\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"csc\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mDTYPE\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    329\u001B[0m         )\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    579\u001B[0m                 \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    580\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 581\u001B[0;31m                 \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_X_y\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    582\u001B[0m             \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    583\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m    962\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"y cannot be None\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    963\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 964\u001B[0;31m     X = check_array(\n\u001B[0m\u001B[1;32m    965\u001B[0m         \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    966\u001B[0m         \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maccept_sparse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[1;32m    744\u001B[0m                     \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0marray\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcasting\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"unsafe\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    745\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 746\u001B[0;31m                     \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    747\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mComplexWarning\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mcomplex_warning\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    748\u001B[0m                 raise ValueError(\n",
      "\u001B[0;31mValueError\u001B[0m: could not convert string to float: 'St Kilda'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jb6_UAG65-Jm"
   },
   "source": [
    "Remainder with estimator"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5lQIptjd35Pp",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:21:43.307271Z",
     "end_time": "2023-05-18T23:21:43.317292Z"
    }
   },
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numerical_transformer, numerical_cols)],\n",
    "       remainder=OneHotEncoder(handle_unknown='ignore', sparse = False)) # alle rimanenti colonne -> applico il OneHotEncoder"
   ],
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rI97aol635LT"
   },
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[\n",
    "                              ('preprocessor', preprocessor),\n",
    "                              ('model', model),\n",
    "                             ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = my_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "score = mean_absolute_error(y_test, preds)\n",
    "print('MAE:', score)"
   ],
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/zk/y_05r4dd4q51x5hx9n0nwwk80000gn/T/ipykernel_1401/2180790006.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;31m# Preprocessing of training data, fit model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m \u001B[0mmy_pipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;31m# Preprocessing of validation data, get predictions\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m    392\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_final_estimator\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;34m\"passthrough\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    393\u001B[0m                 \u001B[0mfit_params_last_step\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfit_params_steps\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msteps\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 394\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_final_estimator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mXt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfit_params_last_step\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    395\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    396\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    448\u001B[0m             \u001B[0;31m# parallel_backend contexts set at a higher level,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    449\u001B[0m             \u001B[0;31m# since correctness does not rely on using threads.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 450\u001B[0;31m             trees = Parallel(\n\u001B[0m\u001B[1;32m    451\u001B[0m                 \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_jobs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    452\u001B[0m                 \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1044\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1045\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1046\u001B[0;31m             \u001B[0;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1047\u001B[0m                 \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1048\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    859\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    860\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 861\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    862\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    863\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    777\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    778\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 779\u001B[0;31m             \u001B[0mjob\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    780\u001B[0m             \u001B[0;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    781\u001B[0m             \u001B[0;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    207\u001B[0m         \u001B[0;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 208\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    209\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    570\u001B[0m         \u001B[0;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    571\u001B[0m         \u001B[0;31m# arguments in memory\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 572\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    573\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    574\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    260\u001B[0m         \u001B[0;31m# change the default number of processes to -1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    261\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 262\u001B[0;31m             return [func(*args, **kwargs)\n\u001B[0m\u001B[1;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[1;32m    264\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    260\u001B[0m         \u001B[0;31m# change the default number of processes to -1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    261\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 262\u001B[0;31m             return [func(*args, **kwargs)\n\u001B[0m\u001B[1;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[1;32m    264\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    214\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    215\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mconfig_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 216\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    217\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    218\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001B[0m in \u001B[0;36m_parallel_build_trees\u001B[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001B[0m\n\u001B[1;32m    183\u001B[0m             \u001B[0mcurr_sample_weight\u001B[0m \u001B[0;34m*=\u001B[0m \u001B[0mcompute_sample_weight\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"balanced\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindices\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mindices\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    184\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 185\u001B[0;31m         \u001B[0mtree\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcurr_sample_weight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcheck_input\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    186\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    187\u001B[0m         \u001B[0mtree\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcheck_input\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[1;32m   1313\u001B[0m         \"\"\"\n\u001B[1;32m   1314\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1315\u001B[0;31m         super().fit(\n\u001B[0m\u001B[1;32m   1316\u001B[0m             \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1317\u001B[0m             \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[1;32m    418\u001B[0m             )\n\u001B[1;32m    419\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 420\u001B[0;31m         \u001B[0mbuilder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuild\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtree_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    421\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    422\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_outputs_\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mis_classifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmDqfp6m7t0F"
   },
   "source": [
    "Alternative techniques to indicate columns"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "raC6aGYM35Et",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:24:23.983677Z",
     "end_time": "2023-05-18T23:24:23.990759Z"
    }
   },
   "source": [
    "X_test.columns.get_indexer(numerical_cols)"
   ],
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 2,  7,  8,  9, 10, 11, 12, 13, 14, 16, 17, 19])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kME5cfj87lbj",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:25:54.421722Z",
     "end_time": "2023-05-18T23:25:54.428224Z"
    }
   },
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numerical_transformer, X.columns.get_indexer(numerical_cols))]) # non cambia nulla a prima"
   ],
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ 1.0000000e+00,  5.0000000e+00,  3.1820000e+03, ...,\n        -3.7859840e+01,  1.4498670e+02,  1.3240000e+04],\n       [ 2.0000000e+00,  8.0000000e+00,  3.0160000e+03, ...,\n        -3.7858000e+01,  1.4490050e+02,  6.3800000e+03],\n       [ 3.0000000e+00,  1.2600000e+01,  3.0200000e+03, ...,\n        -3.7798800e+01,  1.4482200e+02,  3.7550000e+03],\n       ...,\n       [ 4.0000000e+00,  6.7000000e+00,  3.0580000e+03, ...,\n        -3.7735720e+01,  1.4497256e+02,  1.1204000e+04],\n       [ 3.0000000e+00,  1.2000000e+01,  3.0730000e+03, ...,\n        -3.7720570e+01,  1.4502615e+02,  2.1650000e+04],\n       [ 4.0000000e+00,  6.4000000e+00,  3.0110000e+03, ...,\n        -3.7794300e+01,  1.4488750e+02,  7.5700000e+03]])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(X_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Be carefull!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "w912RS-B72X-",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:31:18.873254Z",
     "end_time": "2023-05-18T23:31:18.891977Z"
    }
   },
   "source": [
    "#This code generates a mistake\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Preprocessing for all dataset\n",
    "simple=SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Normalizer()\n",
    "\n",
    "\n",
    "# Bundle preprocessing for numerical\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numerical_transformer, numerical_cols)])\n",
    "\n",
    "# Bundle preprocessing \n",
    "preprocessing_transformer = Pipeline(steps=[('simple', simple),\n",
    "                                            ('preprocessor', preprocessor) # dovrebbe fare un errore perché viene fatta una ricerca per nomi di colonne, che potrebbero non essere presenti se mettiamo il preprocessor dopo il simple -> se lo avessimo messo prima non ci sarebbe stato questo errore\n",
    "                                            ])"
   ],
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4cT-Bgt2-x-S"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gYkUII8e-vEH"
   },
   "source": [
    "preprocessing_transformer.fit_transform(X_train)"
   ],
   "execution_count": 44,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specifying the columns using strings is only supported for pandas DataFrames",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py\u001B[0m in \u001B[0;36m_get_column_indices\u001B[0;34m(X, key)\u001B[0m\n\u001B[1;32m    408\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 409\u001B[0;31m             \u001B[0mall_columns\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    410\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'columns'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/zk/y_05r4dd4q51x5hx9n0nwwk80000gn/T/ipykernel_1401/3598283050.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mpreprocessing_transformer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001B[0m in \u001B[0;36mfit_transform\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m    432\u001B[0m             \u001B[0mfit_params_last_step\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfit_params_steps\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msteps\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    433\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlast_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"fit_transform\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 434\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mlast_step\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mXt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfit_params_last_step\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    435\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    436\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mlast_step\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mXt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfit_params_last_step\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mXt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\u001B[0m in \u001B[0;36mfit_transform\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    670\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_n_features\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    671\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_validate_transformers\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 672\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_validate_column_callables\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    673\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_validate_remainder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    674\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\u001B[0m in \u001B[0;36m_validate_column_callables\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    350\u001B[0m                 \u001B[0mcolumns\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    351\u001B[0m             \u001B[0mall_columns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 352\u001B[0;31m             \u001B[0mtransformer_to_input_indices\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_get_column_indices\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    353\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    354\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_columns\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mall_columns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py\u001B[0m in \u001B[0;36m_get_column_indices\u001B[0;34m(X, key)\u001B[0m\n\u001B[1;32m    409\u001B[0m             \u001B[0mall_columns\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    410\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 411\u001B[0;31m             raise ValueError(\n\u001B[0m\u001B[1;32m    412\u001B[0m                 \u001B[0;34m\"Specifying the columns using strings is only \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    413\u001B[0m                 \u001B[0;34m\"supported for pandas DataFrames\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Specifying the columns using strings is only supported for pandas DataFrames"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FbOWVJ98-vLF",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:31:41.297816Z",
     "end_time": "2023-05-18T23:31:41.304907Z"
    }
   },
   "source": [
    "X_train.columns.get_indexer(numerical_cols)"
   ],
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 2,  7,  8,  9, 10, 11, 12, 13, 14, 16, 17, 19])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_2irXoI--vUP",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:31:47.451761Z",
     "end_time": "2023-05-18T23:31:47.461082Z"
    }
   },
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Preprocessing for all dataset\n",
    "simple=SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Normalizer()\n",
    "\n",
    "\n",
    "# Bundle preprocessing for numerical\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numerical_transformer, X_train.columns.get_indexer(numerical_cols))])\n",
    "\n",
    "# Bundle preprocessing \n",
    "preprocessing_transformer = Pipeline(steps=[('simple', simple),\n",
    "                                            ('preprocessor', preprocessor)\n",
    "                                            ])"
   ],
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-z2lo21y-vbV",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:31:49.013512Z",
     "end_time": "2023-05-18T23:31:49.072409Z"
    }
   },
   "source": [
    "preprocessing_transformer.fit_transform(X_train)"
   ],
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 7.26963825e-05,  3.63481912e-04,  2.31319889e-01, ...,\n        -2.75227341e-03,  1.05400086e-02,  9.62500104e-01],\n       [ 2.72783243e-04,  1.09113297e-03,  4.11357131e-01, ...,\n        -5.16351401e-03,  1.97632142e-02,  8.70178547e-01],\n       [ 5.72636606e-04,  2.40507375e-03,  5.76454183e-01, ...,\n        -7.21499218e-03,  2.76434595e-02,  7.16750152e-01],\n       ...,\n       [ 3.39067054e-04,  5.67937315e-04,  2.59216763e-01, ...,\n        -3.19873485e-03,  1.22888547e-02,  9.49726818e-01],\n       [ 1.36582374e-04,  5.46329495e-04,  1.39905878e-01, ...,\n        -1.71732166e-03,  6.60267194e-03,  9.85669464e-01],\n       [ 4.77479959e-04,  7.63967935e-04,  3.59423039e-01, ...,\n        -4.51150521e-03,  1.72952194e-02,  9.03630823e-01]])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jh8L2_reobmS"
   },
   "source": [
    "## FeatureUnion: Applying multiple transformers in parallel\n",
    "É una terza forma di pipeline.\n",
    "Prende delle pipeline e applica al dataset queste pipeline in parallelo.\n",
    "\n",
    "Concatenates results of multiple transformer objects.\n",
    "\n",
    "This estimator applies a list of transformer objects in parallel to the input data, then concatenates the results. This is useful to combine several feature extraction mechanisms into a single transformer."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jirOU1nHobmT",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:33:47.821700Z",
     "end_time": "2023-05-18T23:33:47.832281Z"
    }
   },
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer"
   ],
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f7jHSp7OobmW",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:33:50.770871Z",
     "end_time": "2023-05-18T23:33:50.781417Z"
    }
   },
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ],
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PXyL4nu5flE1",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:33:51.296649Z",
     "end_time": "2023-05-18T23:33:51.301670Z"
    }
   },
   "source": [
    "iris.feature_names"
   ],
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "['sepal length (cm)',\n 'sepal width (cm)',\n 'petal length (cm)',\n 'petal width (cm)']"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KQbn7EqTobmY",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:33:52.109973Z",
     "end_time": "2023-05-18T23:33:52.116368Z"
    }
   },
   "source": [
    "# This dataset is way too high-dimensional. Better do PCA:\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Maybe some original features where good, too?\n",
    "selection = SelectKBest(k=2) # seleziona le migliori due colonne\n",
    "\n",
    "#Normalizing is always a good choice\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Build estimator from PCA and Univariate selection:\n",
    "\n",
    "combined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection), (\"normal\", scaler)])"
   ],
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ce6C9Q3EgIa4",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:36:00.964218Z",
     "end_time": "2023-05-18T23:36:00.968794Z"
    }
   },
   "source": [
    "X.shape[1]"
   ],
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7osE0a4it7bJ",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:36:10.666957Z",
     "end_time": "2023-05-18T23:36:10.673991Z"
    }
   },
   "source": [
    "pca.fit_transform(X).shape[1]"
   ],
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pDVRsyN1f88J",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:36:11.905650Z",
     "end_time": "2023-05-18T23:36:11.912788Z"
    }
   },
   "source": [
    "selection.fit_transform(X, y).shape[1]"
   ],
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-pyfNLFXgB_N",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:36:14.035996Z",
     "end_time": "2023-05-18T23:36:14.043878Z"
    }
   },
   "source": [
    "scaler.fit_transform(X).shape[1]"
   ],
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "r_W8ifzSobma",
    "ExecuteTime": {
     "start_time": "2023-05-18T23:36:29.008911Z",
     "end_time": "2023-05-18T23:36:29.016016Z"
    }
   },
   "source": [
    "# Use combined features to transform dataset:\n",
    "X_features = combined_features.fit(X, y).transform(X)\n",
    "print(\"Combined space has\", X_features.shape[1], \"features\")"
   ],
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined space has 8 features\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9gwwLKJjobmd"
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = LogisticRegression()\n",
    "\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[('combined_features', combined_features),\n",
    "                              ('model', model)\n",
    "                             ], verbose = True)\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "\n",
    "# Evaluate the model\n",
    "score = accuracy_score(y_valid, preds)\n",
    "print('Accuracy Score:', score)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vn9o0tbbobmg"
   },
   "source": [
    "## FunctionTransformer: Constructs a transformer from an arbitrary callable.\n",
    "Posso stabilire dei trasformatori che voglio io\n",
    "\n",
    "Concatenates results of multiple transformer objects.\n",
    "\n",
    "This estimator applies a list of transformer objects in parallel to the input data, then concatenates the results. This is useful to combine several feature extraction mechanisms into a single transformer."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YotoIWBqobmg"
   },
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "dataset = pd.read_csv(\"melb_data.csv\")\n",
    "columns = dataset.columns.to_list()\n",
    "columns.remove('Price')\n",
    "X = dataset[columns]\n",
    "y = dataset['Price']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)\n",
    "\n",
    "#Selecting the numerical columns\n",
    "def columns_num(X):\n",
    "    numerical_cols = [cname for cname in X.columns if  X[cname].dtype in ['int64', 'float64']]\n",
    "    return X.loc[:,numerical_cols]\n",
    "\n",
    "fill_na_transformer = Pipeline(steps=[ ('drop_cols', FunctionTransformer(columns_num, validate=False)),\n",
    "                                       ('fill_na', SimpleImputer(strategy='most_frequent'))  ], verbose=True)\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', fill_na_transformer),\n",
    "                              ('model', model)\n",
    "                             ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "\n",
    "# Evaluate the model\n",
    "#score = mean_absolute_error(y_valid, preds)\n",
    "#print('MAE:', score)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3G-fIF9meCux"
   },
   "source": [
    "fill_na_transformer.fit_transform(X) "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eStlaWKVR519"
   },
   "source": [
    "fill_na_transformer = Pipeline(steps=[ ('drop_cols', FunctionTransformer(columns_num, validate=True)),\n",
    "                                       ('fill_na', SimpleImputer(strategy='most_frequent'))  ])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aCZBPavrR9-7"
   },
   "source": [
    "fill_na_transformer.fit_transform(X) "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Gv-nhf4RR_dx"
   },
   "source": [
    "columns_num(X)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hezaP5MOTY61"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ]
}
